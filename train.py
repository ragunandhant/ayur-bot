# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12vWqBod5Olfn-HSL7LGnTkwQ1RUBWYuM
"""

!pip install langchain
!pip install huggingface_hub
!pip install sentence_transformers PyPDF textract

!pip install langchain

import os
os.environ["OPENAI_API_KEY"] = "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"
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "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"



from langchain.document_loaders import PyPDFLoader

# Simple method - Split by pages
loader = PyPDFLoader("/content/book.pdf")
pages = loader.load_and_split()
print(pages[0])

# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD
chunks = pages
import textract
doc = textract.process("/content/book.pdf")

# Step 2: Save to .txt and reopen (helps prevent issues)
with open('attention_is_all_you_need.txt', 'w') as f:
    f.write(doc.decode('utf-8'))

from langchain.document_loaders import PyPDFLoader
lst = []
pdf_folder_path = '/content/gdrive/MyDrive/dataset/ayurveda'
for fn in os.listdir(pdf_folder_path):
  loader = PyPDFLoader(os.path.join(pdf_folder_path,fn))
  pages = loader.load_and_split()
  print(pages[0])

  # SKIP TO STEP 2 IF YOU'RE USING THIS METHOD
  chunks = pages
  import textract
  doc = textract.process(os.path.join(pdf_folder_path,fn))

  # Step 2: Save to .txt and reopen (helps prevent issues)
  with open('attention_is_all_you_need.txt', 'a') as f:
      f.write(doc.decode('utf-8'))

# Document Loader
from langchain.document_loaders import TextLoader
loader = TextLoader('attention_is_all_you_need.txt')
documents = loader.load()

documents

import textwrap

def wrap_text_preserve_newlines(text, width=110):
    # Split the input text into lines based on newline characters
    lines = text.split('\n')

    # Wrap each line individually
    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]

    # Join the wrapped lines back together using newline characters
    wrapped_text = '\n'.join(wrapped_lines)

    return wrapped_text

print(wrap_text_preserve_newlines(str(documents[0])))



# Text Splitter
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

len(docs)

docs[0]



"""### Embeddings"""

# Embeddings
from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings()

!pip install faiss-cpu



# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html
from langchain.vectorstores import FAISS

db = FAISS.from_documents(docs, embeddings)

db.save_local("/content/model")

last = FAISS.load_local('/content/model',embeddings)

!zip -r /content/model.zip /content/model

last.similarity_search("what is medicine for cough")

query = "what is gheee"
docs = db.similarity_search(query)

docs

print(wrap_text_preserve_newlines(str(docs[0].page_content)))



"""### Create QA Chain"""

from langchain.chains.question_answering import load_qa_chain
from langchain import HuggingFaceHub

llm=HuggingFaceHub(repo_id="google/flan-t5-xl", model_kwargs={"temperature":0, "max_length":512})

chain = load_qa_chain(llm, chain_type="stuff")



query = "what is ayurvdic"
docs = db.similarity_search(query)
#chain.run(input_documents=docs, question=query)
docs[0].page_content

query = "What did the president say about economy?"
docs = db.similarity_search(query)
chain.run(input_documents=docs, question=query)





"""### Working with PDF Files"""

!pip install unstructured
!pip install chromadb
!pip install Cython
!pip install tiktoken
!pip install unstructured[local-inference]

from langchain.document_loaders import UnstructuredPDFLoader
from langchain.indexes import VectorstoreIndexCreator

# connect your Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

pdf_folder_path = '/content/gdrive/MyDrive/dataset/ayurveda'
os.listdir(pdf_folder_path)

import os
os.remove(os.path.join(pdf_folder_path,".ipynb_checkpoints"))



from langchain.document_loaders import UnstructuredFileLoader
from unstructured.cleaners.core import clean_extra_whitespace

loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]
loaders

index = VectorstoreIndexCreator(
    embedding=HuggingFaceEmbeddings(),
    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(loaders)

llm=HuggingFaceHub(repo_id="google/flan-t5-xl", model_kwargs={"temperature":0, "max_length":512})

from langchain.chains import RetrievalQA
chain = RetrievalQA.from_chain_type(llm=llm,
                                    chain_type="stuff",
                                    retriever=index.vectorstore.as_retriever(),
                                    input_key="question")

!pip install openai

index.query('what is Adiantum incisum Forsk')

chain.run('what is Adiantum incisum Forsk')

chain.run('Who are the authors of GPT4all technical report?')

chain.run('What is the model size of GPT4all?')

